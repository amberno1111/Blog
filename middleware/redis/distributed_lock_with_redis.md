# Distributed Lock with Redis

分布式锁是控制分布式系统中各个节点之间同步访问共享资源的一种方式。因为分布式锁的本质是互斥，只要保证任何时候只有一个客户端可以持有一个锁就可以了。
一般的思路是在获取锁的时候就在某些中间件的实例里创建一个键值，释放锁的时候就把这个键值删除，为了保证锁一定能够释放，一般会给这个键值加上一个失效时间。这些中间件可以是数据库、Zookeeper、Redis等等。

## 基于单Redis节点的分布式锁

大多数时候，我们都会使用这种单Redis节点来实现分布式锁。

首先，使用Redis的setnx命令来争抢锁，然后使用expire命令来设置锁的过期时间以避免锁在某些情况下不被释放。但是这种方法会有点问题，因为有可能系统在setnx之后重启了或者抛异常了，就会导致没有执行expire命令，使得锁永远不会被释放。所以我们都是直接把setnx和expire合并成一条命令来执行的，如下：
```
SET ${target_key} ${target_value} NX PX ${expire_time}
```
其中，NX保证仅当${target_key}不存在时才set值(获取锁)，PX保证能够设置过期时间。

然后计算完毕之后，可以使用DELETE命令释放锁。但是最好也不要仅仅只使用DELETE命令，考虑以下的场景：如果client0拿到lock0之后阻塞了很长一段时间，此时lock0已经过期并且重新分配给了client1，这时候client0再去删除这个锁，明显是一个误操作，导致client1持有的锁被无故释放。为了避免这个问题，最好每个client给这个锁设置的value是不同的(这个锁的key肯定相同)，然后释放锁的时候先做一个判断，如下：
```java
// 伪代码
// 每个客户端都有自己的specific_value
// 在使用SETNX的时候机已经把这个value set进去了
// delete key的时候先对比下value，再决定要不要删除
if getValue(lock_key) == specific_value:
    delete(lock_key)
else
    return
```

**另外，Redis要求释放锁的操作必须使用lua脚本来实现，这样才能保证原子性。**

这个方法只适用于单机版的Redis，如果是master-slave架构的Redis，发生切换时就会存在问题，虽然Redis切换的时候会复制数据，但是这个复制数据的过程是异步的，中间会存在一个时间差。想象一下这个场景：
- client0在master0上拿到了锁
- 在master0将数据copy到slave之前，master0挂了，发生了主从切换，选举出了一个新的master1节点
- client1在master1上拿到了锁，即使这个时候旧的master0上的锁没有过期，也没有被释放

为了解决这个问题，Redis官方提供了一个[RedLock](https://redis.io/topics/distlock)的实现。

## RedLock

RedLock的核心思想是**同时使用多个Redis Master来设置锁，这些Redis节点完全独立，不需要对这些Master节点的数据进行同步，这些Redis Master节点的数量需要是大于2的奇数。**

RedLock获取锁的流程：
- 获取当前系统时间
- 使用SETNX依次尝试获取所有的N个Redis Master节点上的锁
- 如果获取到的锁的数量大于等于(N-1)/2 + 1个，则表示获取锁成功。锁的自动释放时间等于最初的锁释放时间减去获取锁所消耗的时间
- 如果获取到的锁的数量不满足要求，则表示获取锁失败，这时要向所有的Redis Master节点发送释放锁的消息

RedLock释放锁相对来说简单的多，也还是按照上一节的释放锁的方法，向所有的Redis Master节点发送释放锁的消息。


使用RedLock有几个注意事项：
- 重试获取锁的时间间隔应当是一个范围内的随机值，而不是一个固定的值。主要是为了防止多个客户端一起向Redis发送获取锁的请求的情况，这个时候可能会造成大家都获取相同数量的锁，导致效率比较低
- 如果有master节点故障，这个节点恢复的时间应当大于锁的有效时间，想象以下的场景：有三个Redis Master节点R0、R1、R2，client0获取到了R0、R1的锁，这时候R1挂了所有的数据都丢了(client0之前获取的锁直接丢了)，然后R1马上恢复，client1获取了R1、R2的锁。这时候就会发现有两个客户端同时获取到了锁，就会出现问题。如果恢复的时间大于锁的有效时间，就可以避免以上情况发生

## 一些疑问

> 不管有没有成功获取到锁，为什么RedLock强调客户端需要向所有的节点发起锁失效的请求？

来看一下这种场景：客户端发送给某个Redis获取锁的请求，然后Redis加锁成功，但是返回给客户端的响应包可能由于网络抖动之类的原因丢失了，这时候客户端认为是请求超时，并没有加锁成功，但是从Redis来看缺是加锁成功了。所以，**客户端向所有的节点都发起锁失效的请求，就可以正确的处理这种情况。**

> 如果客户端长期阻塞导致锁过期，那么它接下来访问共享资源就会不安全(其他的客户端在这个锁过期后获取了属于它自己的锁，也开始操作访问共享资源)，这时候怎么办？

这篇文章[How to do distributed locking](https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html)提出了这个问题，并提供了解决方案，下面对这篇文章做了一些分析和总结。

首先我们来看一张时序图：
![](https://martin.kleppmann.com/2016/02/unsafe-lock.png)

假设提供锁的服务(lock-service)是没有问题的，它总是能保证任一时刻最多只是有一个客户端能获得锁。
- 客户端1在获取到锁之后，发成了长时间的GC停顿，这时候客户端1锁持有的锁过期了，但是客户端1并不知道，所以继续去访问了共享资源。
- 客户端2在客户端1持有的锁过期了之后，获取到了属于它自己的锁，然后开始了对共享资源的操作。
- 这时候两个客户端同时对共享资源进行了写入操作，就会导致数据出现不一致的问题

那可以不可以让客户端1在访问共享资源之前判断下锁是否过期呢？？答案是不行，这个类似于多线程中的双重检查锁定，是存在问题的。因为上图中的GC暂停很可能正好发生在判断锁过期的代码之后。。。
另外上图中的GC暂停只是一个例子，还有可能其他情况也会导致客户端系统暂停的，也就是说**即使锁服务本身是没有问题的，而仅仅是客户端有长时间的pause或网络延迟，仍然会造成两个客户端同时访问共享资源的冲突情况发生。**


那么如何解决这个问题呢？这篇文章也给出了一个方法，**这个方法叫做fencing token。fencing token是一个递增的数字，当客户端成功获取到锁的时候，fencing token跟随锁一同返回给客户端，而客户端访问共享资源的时候，需要带上这个fencing token，提供共享资源的服务就可以检查fencing token，拒绝掉延迟到来的访问。如下图所示：
![](https://martin.kleppmann.com/2016/02/fencing-tokens.png)



最后，这篇文章还有一个非常重要的知识点，就是对于锁的用途的区分，分为两种：
- 为了效率(efficiency)，协调各个客户端避免做重复的工作。即使锁偶尔失效了，只是可能把某些操作多做一遍而已，不会产生其它的不良后果。比如重复发送了一封同样的email。这种时候直接使用单节点的Redis分布式锁就可以了
- 为了正确性(correctness)。在任何情况下都不允许锁失效的情况发生，因为一旦发生，就可能意味着数据不一致(inconsistency)，数据丢失，文件损坏，或者其它严重的问题。这种场景下，就需要细细考虑分布式锁的安全性了
