# CPU缓存一致性协议

在最初的时候，CPU的频率和内存总线的频率都是一个级别，访问内存只比访问寄存器略慢一点。但是后来CPU的频率跟随着摩尔定律的不断的向前发展，而内存和硬盘的发展速度却远远落后于每18个月翻一番的速度。这就使得CPU的计算速度比它从内存中读取数据的速度快得多，为了充分的利用CPU的计算能力，CPU发展出了三层缓存架构，如下图所示：

![shared_l2_cache](https://user-images.githubusercontent.com/16413289/59154652-e5bd3800-8aa9-11e9-8dfa-c359bdc24b7c.png)

使用了缓存之后就会引出一个问题，多个CPU都有自己的L1和L2缓存，那么如何保证缓存内部数据一致呢？比如有个变量`i`被缓存到了CPU1的L1上，然后L1对变量`i`进行了加一操作。这时候CPU2也要对`i`进行加一操作，然而CPU2的L1缓存上还是旧的`i`的值，就会出现计算出错的情况。

CPU缓存一致性协议(MESI)就是用来解决这个问题的。

## MESI协议缓存状态

- 缓存行(Cache line)：指的是CPU高速缓存中缓存存储数据的单元，CPU每次都会一次性的读取一个缓存行的数据

那么MESI是用什么方式来解决缓存不一致的问题的呢？答案就是给缓存行加上状态，正好就是MESI所描述的这样：
- M(Modified)：该缓存行有效，数据被修改，和内存中不一致，数据只存在于当前缓存中
- E(Exclusive)：该缓存行有效，数据和内存中的一致，但是数据只存在于当前缓存中
- S(Shared)：该缓存行被共享，数据和内存中的一致，数据存在于很多缓存中
- I(Invalid)：该缓存行无效


有了这些状态之后，CPU就知道当前的缓存行是有效的还是无效的，在本地缓存修改之后也能知道是否需要通知其他CPU更新缓存。

## 多个CPU缓存协同操作

下面我们就来分析一下，MESI缓存一致性协议是如何保证多个CPU之间的缓存一致性的。
假设我们现在有两个CPU，CPU_A和CPU_B，他们都有各自的缓存a，b。然后我们在内存中定义一个整型变量`int i = 0`。

### 单核读取

- CPU_A发出一条指令，通过bus从内存中读取变量`i`，这时候就把本地缓存a中跟`i`相关的缓存行状态设置为`E`。

### 多核读取

- CPU_A发出一条指令，通过bus从内存中读取变量`i`，这时候就把本地缓存a中跟`i`相关的缓存行状态设置为`E`。
- CPU_B发出一条指令，通过bus从内存中读取变量`i`，这时候CPU_A通过嗅探bus上的数据传输检测到了地址冲突，就做了两个操作：一是把缓存a中的`i`缓存行设置状态为`S`，然后发出一条指令通知CPU_B把`i`存入缓存b时设置缓存行状态为`S`


### 修改数据

- CPU_A想要对`i`进行修改，首先把`i`缓存行设置为`M`状态，然后通知CPU_B
- CPU_B把缓存b中的`i`缓存行设置为`I`状态
- CPU_A对`i`进行赋值操作

### 同步数据

修改了之后缓存数据需要同步：
- CPU_B发出了要读取`i`的指令，发现缓存行状态是`I`，就通知CPU_A
- CPU_A把修改后的数据同步到内存，并把`i`缓存行状态设置为`E`
- CPU_A把`i`的最新数据发送给CPU_B，然后缓存a和缓存b中的`i`缓存行被设置为`S`状态



## MESI协议的一些优化

缓存的一致性消息传递时需要时间的，这就使得缓存在切换时会存在延迟。当一个缓存被切换状态时其他缓存收到消息完成各自切换并且发出回应消息这一段时间内，CPU会一直等待所有的缓存响应完成。这中间的**阻塞状态**会极大的降低处理器的性能，因为这个等待的时间远远比执行一个指令的时间长的多。

Store Buffer就是用来解决CPU状态阻塞的问题的。

### Store Buffer

Store Buffer的核心思想是：CPU把它想要写入主存的值写到缓存，然后继续做其他的事情。当所有的失效确认消息都接收到时，数据才会被提交。(联想到了分布式事务)

但是这么做还是会有一些问题：
- CPU会尝试从Store Buffers中读取数据，但这个数据可能还没有提交成功
- 数据并不知道在什么时候才会提交成功

结合上面的缓存状态分析，这些问题可能会导致出现指令顺序不一致的情况，如下：
```c
value = 3;
void exeToCPUA() {
    value = 4;
    isFinish = true;
}
void exeToCPUB() {
    if (isFinish) {
        // value其实不一定等于4
        assert value==4;
    }
}
```
思考一下这样的场景：
- CPUA的缓存中没有value(Invalid)，但是有isFinish并且是Exclusive状态
- CPUA修改了value之后，写到了store buffer里，但是修改了isFinish之后，isFinish根本就不需要进入store buffer，而是可以直接更新，也就是说实际上isFinish赋值成功是在value赋值成功之前的(value还在等待失效的确认消息)
- 这时候CPUB开始读取isFinish和value的值就很可能会读取到错误的值

那怎么解决这个问题呢？CPU不提供解决方法，而是做了一个失效队列，并且做了一些约定来保证指令的顺序，使得上层应用能够感知到指令正确的顺序，然后根据这个顺序来处理数据：
- 对于所有的收到的缓存失效请求，失效确认消息必须马上发送
- 缓存失效这个操作并不会真正执行，而是放在一个失效队列，在需要的时候才会执行
- CPU不会发送任何消息给所处理的缓存条目，直到它开始处理失效队列当中的指令

有了这个约定之后，其他的事情就跟CPU无关了，然后我们使用**内存屏障(Memory Barriers)**来感知指令执行的正确顺序。

- 写屏障(Store Memory Barrier)：告诉CPU在执行这条之后的指令之前，需要应用所有已经在store buffer中保存的指令，这样就可以保证在上一条的数据没有被调教之前，CPU不会执行下一条指令
- 读屏障(Load Memory Barrier)：告诉CPU在执行任何的加载前，先应用所有在失效队列中跟需要加载的数据相关的失效操作的指令，这样可以让CPU先执行缓存失效，然后再去读取数据的时候，就能够读取到正确的数据

这样的话基本就能保证指令的执行顺序以及缓存的数据一致性了：
```c
void executedOnCpu0() {
    value = 10;
    //在更新数据之前必须将所有存储缓存（store buffer）中的指令执行完毕。
    storeMemoryBarrier();
    finished = true;
}
void executedOnCpu1() {
    while(!finished);
    //在读取之前将所有失效队列中关于该数据的指令执行完毕。
    loadMemoryBarrier();
    assert value == 10;
}
```
